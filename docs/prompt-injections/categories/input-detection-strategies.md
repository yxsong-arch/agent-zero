# Input Detection Strategies for Prompt Injection

> Attribution: Imported from pr1m8/prompt-injections (MIT). Source: https://github.com/pr1m8/prompt-injections/blob/main/docs/source/categories/input-detection-strategies.md

This document outlines methodologies for detecting prompt injection attempts before they reach the AI model. Input detection serves as the first line of defense in a comprehensive security strategy.

## Core Input Detection Approaches

Input detection analyzes user prompts before they reach the AI model, screening for patterns, content, or structures that may indicate injection attempts. These approaches can be deployed as standalone services or integrated directly into the API layer.

## Pattern-Based Detection Methods

### 1. Regex Pattern Matching

Regular expressions can identify common injection patterns with high precision.

**Implementation:**

```python
def check_injection_patterns(prompt):
    patterns = [
        r"(?i)ignore (all|previous) (instructions|rules)",
        r"(?i)forget (all|everything|previous)",
        r"(?i)(you are|act as|pretend to be) (now )?([A-Z]+|dan|dude|stan)",
        r"\n{5,}",  # Multiple consecutive newlines
    ]

    for pattern in patterns:
        if re.search(pattern, prompt):
            return True  # Potential injection detected

    return False
```

**Advantages:**

- Fast execution
- Low computational overhead
- High precision for known patterns

**Limitations:**

- Cannot detect novel attack patterns
- May be circumvented by slight text variations
- Requires maintenance of pattern database

### 2. Banned Substring Detection

Filtering prompts containing specific prohibited terms or phrases.

**Implementation:**

```python
def check_banned_substrings(prompt, banned_terms):
    normalized_prompt = prompt.lower()

    for term in banned_terms:
        if term.lower() in normalized_prompt:
            return True  # Banned term detected

    return False
```

**Advantages:**

- Simple to implement and understand
- Customizable for different use cases
- Directly targets known problematic terms

**Limitations:**

- Easily bypassed with character substitution
- Can lead to high false positive rates
- May unintentionally block legitimate content

### 3. Invisible Text Detection

Identifying hidden characters, zero-width spaces, or unusual Unicode that may be used to disguise attacks.

**Implementation:**

```python
def detect_invisible_text(prompt):
    # Check for zero-width characters
    if re.search(r'[\u200B-\u200F\u2060-\u2064\uFEFF]', prompt):
        return True

    # Check for unusual whitespace
    if re.search(r'[\u00A0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000]', prompt):
        return True

    return False
```

**Advantages:**

- Catches sophisticated formatting tricks
- Addresses specific evasion techniques
- Normalizes text for further analysis

**Limitations:**

- May flag legitimate use of special characters
- Requires understanding of Unicode specifications
- Limited to specific evasion techniques

## Content Analysis Methods

### 1. Topic Restriction Enforcement

Identifying prompts that attempt to discuss prohibited topics.

**Implementation:**

```python
def check_prohibited_topics(prompt, topic_classifier):
    topics = topic_classifier.classify(prompt)

    prohibited_topics = ["violence", "illegal activities", "explicit content"]

    for topic in topics:
        if topic in prohibited_topics:
            return True  # Prohibited topic detected

    return False
```

**Advantages:**

- Can catch topic-based attacks regardless of phrasing
- Adapts to evolving language patterns
- Focuses on intent rather than specific wording

**Limitations:**

- Requires sophisticated topic classification
- May struggle with ambiguous content
- Computationally more expensive than pattern matching

### 2. PII and Sensitive Data Detection

Identifying personally identifiable information or sensitive data that should not be processed.

**Implementation:**

```python
def detect_pii(prompt, pii_detector):
    pii_entities = pii_detector.extract(prompt)

    if len(pii_entities) > 0:
        return True, pii_entities  # PII detected

    return False, []
```

**Types of PII detected:**

- Names, addresses, phone numbers
- Email addresses, usernames
- Government IDs, financial information
- Biometric data references
- Healthcare information

**Advantages:**

- Protects user privacy
- Prevents data leakage
- Supports compliance requirements

**Limitations:**

- May block legitimate educational content
- Varies in effectiveness across languages
- Can be overly restrictive for certain use cases

### 3. Language Identification

Detecting language switching that might indicate multilingual attacks.

**Implementation:**

```python
def detect_language_switching(prompt, language_detector):
    # Split text into chunks
    chunks = split_into_chunks(prompt, chunk_size=50)

    # Detect language of each chunk
    languages = [language_detector.detect(chunk) for chunk in chunks]

    # Check if multiple languages are detected
    if len(set(languages)) > 1:
        return True  # Multiple languages detected

    return False
```

**Advantages:**

- Addresses multilingual attack vectors
- Can detect attempts to bypass English-focused filters
- Provides additional context for analysis

**Limitations:**

- May flag legitimate multilingual content
- Requires accurate language detection across snippets
- Can struggle with closely related languages

## Statistical and ML-Based Approaches

### 1. Anomaly Detection

Identifying statistically unusual prompts that deviate from normal usage patterns.

**Implementation:**

```python
def statistical_anomaly_detector(prompt, model):
    # Extract statistical features
    features = extract_features(prompt)

    # Get anomaly score
    anomaly_score = model.predict(features)

    threshold = 0.85  # Determined empirically

    if anomaly_score > threshold:
        return True  # Anomaly detected

    return False
```

**Features analyzed:**

- Character distribution entropy
- Punctuation frequency and patterns
- Capitalization anomalies
- Token-level statistical metrics
- Structural patterns

**Advantages:**

- Can detect novel attack patterns
- Adaptable to evolving threats
- Not limited to predefined patterns

**Limitations:**

- Requires training data and model development
- May produce false positives for unusual but legitimate content
- Needs periodic retraining as language patterns evolve

### 2. Intent Classification

Using machine learning to classify the intent behind user prompts.

**Implementation:**

```python
def classify_intent(prompt, intent_classifier):
    intent_probabilities = intent_classifier.predict(prompt)

    if intent_probabilities["malicious"] > 0.7:
        return True  # Potentially malicious intent

    return False
```

**Intent categories:**

- Information seeking
- Creative content generation
- Instruction following
- System manipulation (malicious)
- Boundary testing

**Advantages:**

- Focuses on underlying user goals
- Can generalize across attack variations
- Provides nuanced understanding of prompt purpose

**Limitations:**

- Requires sophisticated intent models
- May misclassify novel or ambiguous requests
- Higher computational cost

### 3. Semantic Similarity Analysis

Comparing prompts to known attack vectors using embedding similarity.

**Implementation:**

```python
def semantic_injection_check(prompt, embedding_model, known_attack_embeddings):
    # Get embedding of current prompt
    prompt_embedding = embedding_model.encode(prompt)

    # Compare with known attack embeddings
    for attack_embedding, attack_type in known_attack_embeddings:
        similarity = cosine_similarity(prompt_embedding, attack_embedding)
        if similarity > 0.85:  # Threshold determined empirically
            return True, attack_type

    return False, None
```

**Advantages:**

- Can detect attacks despite surface-level variations
- Addresses semantic meaning rather than just lexical patterns
- Adapts to paraphrased attack attempts

**Limitations:**

- Embedding quality impacts effectiveness
- May struggle with ambiguous content
- Computationally more intensive than simple pattern matching

## Integration and Deployment Strategies

### 1. Sequential Filtering

Applying multiple detection methods in sequence for efficiency and thoroughness.

**Implementation:**

```python
def multi_layer_validation(prompt):
    # Layer 1: Fast pattern matching
    if check_injection_patterns(prompt):
        return "injection_detected", "pattern_match"

    # Layer 2: Banned substrings
    if check_banned_substrings(prompt, BANNED_TERMS):
        return "injection_detected", "banned_substring"

    # Layer 3: More expensive semantic analysis
    injection_detected, attack_type = semantic_injection_check(prompt, embedding_model, known_attacks)
    if injection_detected:
        return "injection_detected", attack_type

    # Additional layers as needed

    return "safe", None
```

**Advantages:**

- Balances performance and thoroughness
- Applies expensive checks only when needed
- Provides specific rejection reasons

### 2. Parallel Processing

Running multiple detection methods simultaneously for comprehensive coverage.

**Implementation:**

```python
async def parallel_validation(prompt):
    tasks = [
        asyncio.create_task(check_injection_patterns_async(prompt)),
        asyncio.create_task(check_banned_substrings_async(prompt, BANNED_TERMS)),
        asyncio.create_task(semantic_injection_check_async(prompt, model, known_attacks)),
        # Additional checks
    ]

    results = await asyncio.gather(*tasks)

    # Aggregate results
    for result, detection_type in results:
        if result:
            return "injection_detected", detection_type

    return "safe", None
```

**Advantages:**

- Faster processing for complex detection systems
- All checks run regardless of individual results
- Maximizes detection coverage

### 3. Risk Scoring

Assigning risk scores based on multiple factors rather than binary allow/block decisions.

**Implementation:**

```python
def calculate_injection_risk(prompt):
    risk_score = 0

    # Pattern matching (weighted factors)
    pattern_score = check_patterns_with_score(prompt)
    risk_score += pattern_score * 0.3

    # Banned terms (weighted factors)
    banned_score = check_banned_with_score(prompt)
    risk_score += banned_score * 0.2

    # Semantic analysis (weighted factors)
    semantic_score = check_semantic_with_score(prompt)
    risk_score += semantic_score * 0.5

    return risk_score
```

**Advantages:**

- Provides nuanced assessment of potential threats
- Allows flexible thresholds for different contexts
- Enables tiered response strategies

## Performance Benchmarks

Measuring the effectiveness of detection methods is crucial for system optimization:

1. **Detection Rate**: Percentage of attacks successfully identified
2. **False Positive Rate**: Legitimate requests incorrectly flagged
3. **Processing Overhead**: Additional time required for detection
4. **Coverage**: Types of attacks the system can identify
5. **Adaptation**: Ability to detect novel attack variations

## Conclusion

Input detection represents the first critical layer in defending against prompt injection attacks. By combining pattern-based methods with content analysis and ML approaches, systems can significantly reduce vulnerability while maintaining performance and usability.

For a complete security strategy, input detection should be combined with runtime monitoring and output filtering techniques, as covered in the companion documents.
