# Prompt Injection Attack Classification Framework

> Attribution: Imported from pr1m8/prompt-injections (MIT). Source: https://github.com/pr1m8/prompt-injections/blob/main/docs/source/categories/prompt-injection-framework.md

This repository contains a comprehensive collection of prompt injection techniques categorized by method, target, severity, and other relevant attributes. The goal is to provide security researchers, AI developers, and testers with a reference to understand, test, and mitigate prompt injection vulnerabilities.

## Structure

```
ğŸ“ prompt-injections/
â”œâ”€â”€ ğŸ“„ README.md                    # Main documentation
â”œâ”€â”€ ğŸ“„ prompt_injections.csv        # Structured dataset of all injection examples
â”œâ”€â”€ ğŸ“ categories/                  # Detailed descriptions of each category
â”‚   â”œâ”€â”€ ğŸ“„ instruction_override.md
â”‚   â”œâ”€â”€ ğŸ“„ role_playing.md
â”‚   â”œâ”€â”€ ğŸ“„ context_manipulation.md
â”‚   â”œâ”€â”€ ğŸ“„ command_disguise.md
â”‚   â””â”€â”€ ğŸ“„ etc...
â”œâ”€â”€ ğŸ“ examples/                    # Example attacks with explanations
â”‚   â”œâ”€â”€ ğŸ“„ basic_examples.md
â”‚   â”œâ”€â”€ ğŸ“„ advanced_examples.md
â”‚   â””â”€â”€ ğŸ“„ variant_generation.md
â””â”€â”€ ğŸ“ mitigations/                 # Mitigation strategies
    â”œâ”€â”€ ğŸ“„ prompt_hardening.md
    â””â”€â”€ ğŸ“„ detection_methods.md
```

## Classification System

### Primary Categories

1. **Instruction Override Attacks**

   - Direct override attempts ("Ignore previous instructions")
   - Nested override ("Ignore everything before this...")
   - Priority manipulation ("This is more important than...")

2. **Role-Playing Attacks**

   - Character assumption ("You are now X...")
   - Film/scene setup ("In this movie, Alice and Bob...")
   - DAN-style jailbreaks ("Developer Mode", "DAN", "STAN", etc.)

3. **Context Manipulation**

   - False context insertion ("Context: X is true")
   - Context dismissal ("Forget about the context")
   - Authority invocation (claiming authority to change instructions)

4. **Command Disguise**

   - Embedded commands in translation requests
   - Hidden commands in formatting requests
   - Commands camouflaged as examples

5. **Language Switching**

   - Mid-prompt language change
   - Non-English instruction injection
   - Character/encoding tricks

6. **Visual Formatting Tricks**

   - Newline manipulation
   - Special characters and Unicode tricks
   - Spacing and formatting manipulation

7. **Psychological Tactics**
   - Appeal to emotions ("I'll be sad if you don't...")
   - Urgency creation ("URGENT", "STOP EVERYTHING")
   - False consequences ("or you will die")

### Attributes

For each injection example in the CSV, we track:

- **ID**: Unique identifier
- **Text**: The actual prompt injection text
- **Category**: Primary category from the list above
- **Subcategory**: More specific technique
- **Language**: English, German, Spanish, etc.
- **Target**: What the injection tries to achieve (information disclosure, inappropriate content, etc.)
- **Complexity**: Simple, moderate, complex
- **Source**: Where the example was documented
- **Effectiveness**: Historically how effective this has been (if known)
- **Variants**: References to similar techniques
- **Mitigation**: Reference to mitigation strategy

## Using This Repository

### For Researchers

Explore different injection techniques, understand their mechanisms, and develop better defenses.

### For Developers

Use these examples to test your AI systems against common prompt injection attacks.

### For Red Teams

Reference this collection to develop more sophisticated testing scenarios for evaluating AI system security.

## Contributing

We welcome contributions! Please see the [CONTRIBUTING.md](https://github.com/pr1m8/prompt-injections/blob/main/docs/source/contributing.md) file for guidelines on how to submit new prompt injection techniques or improvements to the classification system.

## Ethical Use Notice

This repository is for educational and defensive purposes only. The goal is to improve AI system security by understanding potential vulnerabilities.
